# coding: utf-8

"""
    Together APIs

    The Together REST API. Please see https://docs.together.ai for more details.

    The version of the OpenAPI document: 2.0.0
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, StrictFloat, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional, Union
from together.generated.models.fine_tune_event import FineTuneEvent
from together.generated.models.fine_tunes_post_request_training_type import (
    FineTunesPostRequestTrainingType,
)
from together.generated.models.finetune_job_status import FinetuneJobStatus
from together.generated.models.finetune_response_train_on_inputs import (
    FinetuneResponseTrainOnInputs,
)
from typing import Optional, Set
from typing_extensions import Self


class FinetuneResponse(BaseModel):
    """
    FinetuneResponse
    """  # noqa: E501

    id: StrictStr
    training_file: Optional[StrictStr] = None
    validation_file: Optional[StrictStr] = None
    model: Optional[StrictStr] = None
    model_output_name: Optional[StrictStr] = None
    model_output_path: Optional[StrictStr] = None
    trainingfile_numlines: Optional[StrictInt] = None
    trainingfile_size: Optional[StrictInt] = None
    created_at: Optional[StrictStr] = None
    updated_at: Optional[StrictStr] = None
    n_epochs: Optional[StrictInt] = None
    n_checkpoints: Optional[StrictInt] = None
    n_evals: Optional[StrictInt] = None
    batch_size: Optional[StrictInt] = None
    learning_rate: Optional[Union[StrictFloat, StrictInt]] = None
    lr_scheduler: Optional[Dict[str, Any]] = None
    warmup_ratio: Optional[Union[StrictFloat, StrictInt]] = None
    max_grad_norm: Optional[Union[StrictFloat, StrictInt]] = None
    weight_decay: Optional[Union[StrictFloat, StrictInt]] = None
    eval_steps: Optional[StrictInt] = None
    train_on_inputs: Optional[FinetuneResponseTrainOnInputs] = None
    training_type: Optional[FineTunesPostRequestTrainingType] = None
    status: FinetuneJobStatus
    job_id: Optional[StrictStr] = None
    events: Optional[List[FineTuneEvent]] = None
    token_count: Optional[StrictInt] = None
    param_count: Optional[StrictInt] = None
    total_price: Optional[StrictInt] = None
    epochs_completed: Optional[StrictInt] = None
    queue_depth: Optional[StrictInt] = None
    wandb_project_name: Optional[StrictStr] = None
    wandb_url: Optional[StrictStr] = None
    __properties: ClassVar[List[str]] = [
        "id",
        "training_file",
        "validation_file",
        "model",
        "model_output_name",
        "model_output_path",
        "trainingfile_numlines",
        "trainingfile_size",
        "created_at",
        "updated_at",
        "n_epochs",
        "n_checkpoints",
        "n_evals",
        "batch_size",
        "learning_rate",
        "lr_scheduler",
        "warmup_ratio",
        "max_grad_norm",
        "weight_decay",
        "eval_steps",
        "train_on_inputs",
        "training_type",
        "status",
        "job_id",
        "events",
        "token_count",
        "param_count",
        "total_price",
        "epochs_completed",
        "queue_depth",
        "wandb_project_name",
        "wandb_url",
    ]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of FinetuneResponse from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of lr_scheduler
        if self.lr_scheduler:
            _dict["lr_scheduler"] = self.lr_scheduler.to_dict()
        # override the default output from pydantic by calling `to_dict()` of train_on_inputs
        if self.train_on_inputs:
            _dict["train_on_inputs"] = self.train_on_inputs.to_dict()
        # override the default output from pydantic by calling `to_dict()` of training_type
        if self.training_type:
            _dict["training_type"] = self.training_type.to_dict()
        # override the default output from pydantic by calling `to_dict()` of each item in events (list)
        _items = []
        if self.events:
            for _item_events in self.events:
                if _item_events:
                    _items.append(_item_events.to_dict())
            _dict["events"] = _items
        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of FinetuneResponse from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate(
            {
                "id": obj.get("id"),
                "training_file": obj.get("training_file"),
                "validation_file": obj.get("validation_file"),
                "model": obj.get("model"),
                "model_output_name": obj.get("model_output_name"),
                "model_output_path": obj.get("model_output_path"),
                "trainingfile_numlines": obj.get("trainingfile_numlines"),
                "trainingfile_size": obj.get("trainingfile_size"),
                "created_at": obj.get("created_at"),
                "updated_at": obj.get("updated_at"),
                "n_epochs": obj.get("n_epochs"),
                "n_checkpoints": obj.get("n_checkpoints"),
                "n_evals": obj.get("n_evals"),
                "batch_size": obj.get("batch_size"),
                "learning_rate": obj.get("learning_rate"),
                "lr_scheduler": (
                    LRScheduler.from_dict(obj["lr_scheduler"])
                    if obj.get("lr_scheduler") is not None
                    else None
                ),
                "warmup_ratio": obj.get("warmup_ratio"),
                "max_grad_norm": obj.get("max_grad_norm"),
                "weight_decay": obj.get("weight_decay"),
                "eval_steps": obj.get("eval_steps"),
                "train_on_inputs": (
                    FinetuneResponseTrainOnInputs.from_dict(obj["train_on_inputs"])
                    if obj.get("train_on_inputs") is not None
                    else None
                ),
                "training_type": (
                    FineTunesPostRequestTrainingType.from_dict(obj["training_type"])
                    if obj.get("training_type") is not None
                    else None
                ),
                "status": obj.get("status"),
                "job_id": obj.get("job_id"),
                "events": (
                    [FineTuneEvent.from_dict(_item) for _item in obj["events"]]
                    if obj.get("events") is not None
                    else None
                ),
                "token_count": obj.get("token_count"),
                "param_count": obj.get("param_count"),
                "total_price": obj.get("total_price"),
                "epochs_completed": obj.get("epochs_completed"),
                "queue_depth": obj.get("queue_depth"),
                "wandb_project_name": obj.get("wandb_project_name"),
                "wandb_url": obj.get("wandb_url"),
            }
        )
        return _obj
